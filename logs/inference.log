[2025-04-13 21:14:15.067789] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: æƒ…æŠ¥æ¥æºï¼š@è´¢ç»ç½‘
[2025-04-13 21:17:25.815759] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-13 21:17:41.643145] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-13 21:22:20.559818] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp --> PRED: negative
[2025-04-13 21:22:58.382574] TEXT: ç¾è”å‚¨å®£å¸ƒåŠ æ¯50bp --> PRED: negative
[2025-04-13 21:24:00.052713] TEXT: ç¾è‚¡ä¸Šæ¶¨10% --> PRED: positive
[2025-04-14 14:25:12.340980] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:26:59.271982] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:28:01.873511] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:29:59.529952] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:31:01.477234] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:31:41.804649] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:36:03.834550] TEXT: ç¾è‚¡ä¸‰å¤§æŒ‡æ•°è·³æ°´ï¼ŒæŠ•èµ„è€…ææ…ŒåŠ å‰§ --> PRED: negative
[2025-04-14 14:38:34.281672] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…å…´å¥‹ --> PRED: negative
[2025-04-14 14:38:59.166819] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨ --> PRED: negative
[2025-04-14 14:39:18.039242] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 14:43:56.382787] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 14:47:21.445776] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 14:48:53.328424] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 14:50:00.303851] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 14:52:04.379005] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: positive
[2025-04-14 15:01:12.875232] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: neutral
[2025-04-14 15:01:22.980187] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: neutral
[2025-04-14 16:24:09,492] INFO: ğŸš€ Flask app initialized.
[2025-04-14 16:24:09,493] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight
[2025-04-14 16:24:09,493] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-14 16:24:38,765] INFO: ğŸš€ Flask app initialized.
[2025-04-14 16:24:38,765] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight/final
[2025-04-14 16:24:38,765] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-14 16:24:39,857] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpd5h6ct3k/test.c -o /tmp/tmpd5h6ct3k/test.o
[2025-04-14 16:24:39,882] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpd5h6ct3k/test.o -laio -o /tmp/tmpd5h6ct3k/a.out
[2025-04-14 16:24:40,245] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmp6qwo58q5/test.c -o /tmp/tmp6qwo58q5/test.o
[2025-04-14 16:24:40,266] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmp6qwo58q5/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmp6qwo58q5/a.out
[2025-04-14 16:24:40,848] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-14 16:24:40,849] INFO: ğŸš€ Starting Flask inference server...
[2025-04-14 16:24:40,955] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-14 16:24:40,955] INFO: [33mPress CTRL+C to quit[0m
[2025-04-14 16:24:49,132] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-14 16:24:49,756] INFO: âœ… Prediction: negative | â±ï¸ Inference time: 624.45 ms
[2025-04-14 16:24:49,756] INFO: 127.0.0.1 - - [14/Apr/2025 16:24:49] "POST /predict HTTP/1.1" 200 -
[2025-04-14 16:24:55,329] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-14 16:24:55,430] INFO: âœ… Prediction: negative | â±ï¸ Inference time: 100.79 ms
[2025-04-14 16:24:55,430] INFO: 127.0.0.1 - - [14/Apr/2025 16:24:55] "POST /predict HTTP/1.1" 200 -
[2025-04-14 16:53:32,165] INFO: ğŸš€ Flask app initialized.
[2025-04-14 16:53:32,165] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight_v2/final
[2025-04-14 16:53:32,165] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-14 16:54:15,374] INFO: ğŸš€ Flask app initialized.
[2025-04-14 16:54:15,374] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion/final
[2025-04-14 16:54:15,374] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-14 16:54:16,492] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpst71emt9/test.c -o /tmp/tmpst71emt9/test.o
[2025-04-14 16:54:16,508] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpst71emt9/test.o -laio -o /tmp/tmpst71emt9/a.out
[2025-04-14 16:54:16,871] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpg9t36tap/test.c -o /tmp/tmpg9t36tap/test.o
[2025-04-14 16:54:16,883] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpg9t36tap/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmpg9t36tap/a.out
[2025-04-14 16:54:17,486] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-14 16:54:17,486] INFO: ğŸš€ Starting Flask inference server...
[2025-04-14 16:54:17,590] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-14 16:54:17,590] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 11:00:51.236432] TEXT: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, è‚¡ç¥¨å¸‚åœºå¤§æ¶¨ --> PRED: neutral
[2025-04-15 11:02:00,673] INFO: ğŸš€ Flask app initialized.
[2025-04-15 11:02:00,673] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion/final
[2025-04-15 11:02:00,673] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-15 11:02:01,705] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmp11rljg_3/test.c -o /tmp/tmp11rljg_3/test.o
[2025-04-15 11:02:01,723] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmp11rljg_3/test.o -laio -o /tmp/tmp11rljg_3/a.out
[2025-04-15 11:02:02,102] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmptacl9zmt/test.c -o /tmp/tmptacl9zmt/test.o
[2025-04-15 11:02:02,118] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmptacl9zmt/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmptacl9zmt/a.out
[2025-04-15 11:02:02,972] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-15 11:02:02,973] INFO: ğŸš€ Starting Flask inference server...
[2025-04-15 11:02:03,079] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-15 11:02:03,079] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 11:02:26,303] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 11:02:26,976] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 673.38 ms
[2025-04-15 11:02:26,977] INFO: 127.0.0.1 - - [15/Apr/2025 11:02:26] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:45:51,975] INFO: ğŸš€ Flask app initialized.
[2025-04-15 16:45:51,975] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight_response/final
[2025-04-15 16:45:51,975] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-15 16:45:53,003] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpy2lk3z3y/test.c -o /tmp/tmpy2lk3z3y/test.o
[2025-04-15 16:45:53,023] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpy2lk3z3y/test.o -laio -o /tmp/tmpy2lk3z3y/a.out
[2025-04-15 16:45:53,367] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpa75l9g11/test.c -o /tmp/tmpa75l9g11/test.o
[2025-04-15 16:45:53,384] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpa75l9g11/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmpa75l9g11/a.out
[2025-04-15 16:45:53,982] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-15 16:45:53,982] INFO: ğŸš€ Starting Flask inference server...
[2025-04-15 16:45:54,088] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-15 16:45:54,088] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 16:46:05,202] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:46:05,915] INFO: âœ… Prediction: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨ | â±ï¸ Inference time: 713.53 ms
[2025-04-15 16:46:05,916] INFO: 127.0.0.1 - - [15/Apr/2025 16:46:05] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:47:17,883] INFO: ğŸš€ Flask app initialized.
[2025-04-15 16:47:17,884] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight_response/final
[2025-04-15 16:47:17,884] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-15 16:47:18,914] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpch34ya3m/test.c -o /tmp/tmpch34ya3m/test.o
[2025-04-15 16:47:18,932] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpch34ya3m/test.o -laio -o /tmp/tmpch34ya3m/a.out
[2025-04-15 16:47:19,286] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpgf_x37e1/test.c -o /tmp/tmpgf_x37e1/test.o
[2025-04-15 16:47:19,304] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpgf_x37e1/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmpgf_x37e1/a.out
[2025-04-15 16:47:19,893] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-15 16:47:19,894] INFO: ğŸš€ Starting Flask inference server...
[2025-04-15 16:47:19,898] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-15 16:47:19,898] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 16:47:22,789] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:47:23,428] INFO: âœ… Prediction: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨ | â±ï¸ Inference time: 639.5 ms
[2025-04-15 16:47:23,429] INFO: 127.0.0.1 - - [15/Apr/2025 16:47:23] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:49:37,951] INFO: ğŸš€ Flask app initialized.
[2025-04-15 16:49:37,951] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight_response/final
[2025-04-15 16:49:37,952] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-15 16:49:38,987] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpvnv_jmfm/test.c -o /tmp/tmpvnv_jmfm/test.o
[2025-04-15 16:49:39,006] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpvnv_jmfm/test.o -laio -o /tmp/tmpvnv_jmfm/a.out
[2025-04-15 16:49:39,352] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpvuyuewrz/test.c -o /tmp/tmpvuyuewrz/test.o
[2025-04-15 16:49:39,374] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpvuyuewrz/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmpvuyuewrz/a.out
[2025-04-15 16:49:39,951] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-15 16:49:39,951] INFO: ğŸš€ Starting Flask inference server...
[2025-04-15 16:49:40,056] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-15 16:49:40,057] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 16:49:47,429] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:49:48,084] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 655.09 ms
[2025-04-15 16:49:48,084] INFO: 127.0.0.1 - - [15/Apr/2025 16:49:48] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:51:49,632] INFO: ğŸš€ Flask app initialized.
[2025-04-15 16:51:49,632] INFO: ğŸ”§ Loading model from: /usr1/home/s124mdg41_08/dev/Capstone/models/qwen_lora_emotion_weight_response/final
[2025-04-15 16:51:49,632] INFO: ğŸ–¥ï¸ Using device: cuda
[2025-04-15 16:51:50,682] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpx8r0bl9r/test.c -o /tmp/tmpx8r0bl9r/test.o
[2025-04-15 16:51:50,699] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpx8r0bl9r/test.o -laio -o /tmp/tmpx8r0bl9r/a.out
[2025-04-15 16:51:51,050] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -O2 -isystem /usr1/home/s124mdg41_08/miniconda3/include -fPIC -c /tmp/tmpc46rsbho/test.c -o /tmp/tmpc46rsbho/test.o
[2025-04-15 16:51:51,067] INFO: gcc -pthread -B /usr1/home/s124mdg41_08/miniconda3/compiler_compat /tmp/tmpc46rsbho/test.o -L/usr/local/cuda-12.0 -L/usr/local/cuda-12.0/lib64 -lcufile -o /tmp/tmpc46rsbho/a.out
[2025-04-15 16:51:51,662] INFO: âœ… Model and tokenizer loaded successfully.
[2025-04-15 16:51:51,663] INFO: ğŸš€ Starting Flask inference server...
[2025-04-15 16:51:51,768] INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://10.97.27.241:8000
[2025-04-15 16:51:51,768] INFO: [33mPress CTRL+C to quit[0m
[2025-04-15 16:51:53,948] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:51:54,579] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 630.86 ms
[2025-04-15 16:51:54,579] INFO: 127.0.0.1 - - [15/Apr/2025 16:51:54] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:51:56,050] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:51:56,152] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 101.67 ms
[2025-04-15 16:51:56,152] INFO: 127.0.0.1 - - [15/Apr/2025 16:51:56] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:51:57,619] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:51:57,718] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 99.33 ms
[2025-04-15 16:51:57,718] INFO: 127.0.0.1 - - [15/Apr/2025 16:51:57] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:51:58,535] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:51:58,631] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 96.69 ms
[2025-04-15 16:51:58,631] INFO: 127.0.0.1 - - [15/Apr/2025 16:51:58] "POST /predict HTTP/1.1" 200 -
[2025-04-15 16:51:59,364] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨
[2025-04-15 16:51:59,464] INFO: âœ… Prediction: neutral | â±ï¸ Inference time: 99.92 ms
[2025-04-15 16:51:59,464] INFO: 127.0.0.1 - - [15/Apr/2025 16:51:59] "POST /predict HTTP/1.1" 200 -
[2025-04-15 17:02:12,171] INFO: ğŸ“¨ Received text: ç¾è”å‚¨å®£å¸ƒé™æ¯50bp, æŠ•èµ„è€…çº·çº·ä¹°å…¥è‚¡ç¥¨ï¼Œè‚¡å¸‚å¤§æ¶¨ï¼
[2025-04-15 17:02:12,285] INFO: âœ… Prediction: positive | â±ï¸ Inference time: 113.98 ms
[2025-04-15 17:02:12,285] INFO: 127.0.0.1 - - [15/Apr/2025 17:02:12] "POST /predict HTTP/1.1" 200 -
