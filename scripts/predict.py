import os
import argparse
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from datetime import datetime
from utils.utils import classify_emotion
from config.config import DEVICE


def parse_args():
    parser = argparse.ArgumentParser(description="æƒ…ç»ªåˆ†ç±»æŽ¨ç† CLI")

    parser.add_argument("--text", type=str, required=True, help="è¾“å…¥æ–‡æœ¬")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡åž‹è·¯å¾„ï¼ˆåŒ…å« LoRA æƒé‡ï¼‰")
    parser.add_argument("--log_path", type=str, default=None, help="å¯é€‰ï¼šä¿å­˜é¢„æµ‹æ—¥å¿—çš„è·¯å¾„")

    return parser.parse_args()

def main():
    args = parse_args()

    # åŠ è½½ tokenizer å’Œæ¨¡åž‹
    device = DEVICE
    tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True, local_files_only=True)
    model = AutoModelForCausalLM.from_pretrained(
        args.model_path, 
        trust_remote_code=True, 
        torch_dtype=torch.bfloat16, 
        attn_implementation="flash_attention_2", 
        local_files_only=True).to(device)

    model.eval()
    
    pred = classify_emotion(args.text, model, tokenizer, device, cli=True)

    # è¾“å‡ºç»“æžœ
    print("="*40)
    print(f"ðŸ“ è¾“å…¥æ–‡æœ¬: {args.text}")
    print(f"ðŸ“Š é¢„æµ‹æƒ…ç»ª: \033[92m{pred}\033[0m")  # ç»¿è‰²é«˜äº®
    print("="*40)

    # æ—¥å¿—è®°å½•ï¼ˆå¯é€‰ï¼‰
    if args.log_path:
        os.makedirs(os.path.dirname(args.log_path), exist_ok=True)
        with open(args.log_path, "a", encoding="utf-8") as f:
            log_line = f"[{datetime.now()}] TEXT: {args.text} --> PRED: {pred}\n"
            f.write(log_line)

if __name__ == "__main__":
    main()

